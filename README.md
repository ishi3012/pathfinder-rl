# Reinforcement Learning Projects


ğŸš€ A collection of Reinforcement Learning (RL) projects implementing Q-Learning, Deep Q-Networks (DQN), and Policy Gradient methods in various environments. Each project showcases different RL concepts with implementations in Python, OpenAI Gym, TensorFlow/PyTorch, and web-based applications.

## ğŸ“Œ Projects in Repository

This repository currently contains the following RL projects:

| ğŸ“ Project          | ğŸ† Algorithm               | ğŸ–¥ï¸ Implementation                    |
|---------------------|--------------------------|--------------------------------------|
| **CliffWalking-RL** | Q-Learning               | OpenAI Gym, NumPy                   |
| **TicTacToe-DQN-AI** | Deep Q-Networks (DQN)    | PyTorch, Streamlit  |
| **Snake-RL**        | Deep Q-Learning          | PyTorch, Pygame                     |

More projects will be added over time! ğŸš€

## ğŸ“‚ Repository Structure
```
ğŸ“‚ RL-Projects-Portfolio (Root Repository) 
â”‚
â”œâ”€â”€ ğŸ“‚ CliffWalking-RL (Cliff Walking using Q-Learning)
â”‚       â”œâ”€â”€ ğŸ“‚ src (Python code)
â”‚       â”œâ”€â”€ ğŸ“‚ logs (Training logs)
â”‚       â”œâ”€â”€ ğŸ“œ README.md (Project documentation)
â”‚
â”œâ”€â”€ ğŸ“‚ TicTacToe-DQN-AI (Tic-Tac-Toe AI using Deep Q-Networks)
â”‚       â”œâ”€â”€ ğŸ“‚ src (Source code: training, GUI, web app)
â”‚       â”œâ”€â”€ ğŸ“‚ models (Saved trained models)
â”‚       â”œâ”€â”€ ğŸ“‚ web (Web frontend for Flask & Streamlit)
â”‚       â”œâ”€â”€ ğŸ“‚ logs (Training logs)
â”‚       â”œâ”€â”€ ğŸ“œ README.md (Project documentation)
â”‚
â”œâ”€â”€ ğŸ“‚ Snake-RL (Snake game AI using Deep Q-Learning)
â”‚       â”œâ”€â”€ ğŸ“‚ src (Python code for training & playing)
â”‚       â”œâ”€â”€ ğŸ“‚ models (Saved trained models)
â”‚       â”œâ”€â”€ ğŸ“œ README.md (Project documentation)
â”‚
â”œâ”€â”€ ğŸ“œ README.md (This file - Main repository documentation)
â”œâ”€â”€ ğŸ“œ LICENSE (License for the repository)
```

## ğŸ“¥ Installation & Setup

### ğŸ”¹ Clone the Repository
```
git clone https://github.com/YOUR_USERNAME/RL-Projects-Portfolio.git
cd RL-Projects-Portfolio
```

### ğŸ”¹ Install Dependencies
```
cd TicTacToe-DQN-AI
pip install -r requirements.txt

```

## ğŸš€ Running the Projects

### 1ï¸âƒ£ CliffWalking-RL (Q-Learning)
Description: An AI learns to walk across a dangerous cliff without falling using Q-learning.

Run Training
```
cd CliffWalking-RL/src
python train_q_learning.py
```
Run AI Agent
```
python play_q_learning.py
```

### 2ï¸âƒ£ Tic-Tac-Toe AI (DQN)
Description: A Deep Q-Networks (DQN) based AI that learns to play Tic-Tac-Toe through reinforcement learning.

Run Training
```
cd TicTacToe-DQN-AI/src
python train_dqn.py
```
Play Against AI (CLI Version)
```
python play_vs_ai.py
```
Run GUI Version
```
python gui_tictactoe.py
```

Run Web App (Flask)
```
cd TicTacToe-DQN-AI
python app.py
```
Open http://127.0.0.1:5000/ in your browser.

Run Web App (Streamlit)
```
streamlit run streamlit_app.py
```
### 3ï¸âƒ£ Snake Game AI (DQN)
Description: The Snake Game AI learns to play the classic Snake Game using Deep Q-Learning.

Run Training
```
cd Snake-RL/src
python train_snake.py
```
Run AI Agent
```
python play_snake.py
```
Run GUI Version
```
python gui_snake.py
```

## ğŸ“Š Visualizing AI Training

Each project includes a training visualization script that plots the AI's learning progress.

Example for Tic-Tac-Toe AI:
```
python visualize_training.py
```

## ğŸŒ Deployment Options
- âœ… Flask & Render: Deploy Tic-Tac-Toe AI using Flask + Render.com
- âœ… Streamlit Cloud: Deploy Tic-Tac-Toe AI on Streamlit Sharing
- âœ… GitHub Actions: Automate training updates & deployment

## ğŸ› ï¸ Customization
- Modify hyperparameters (learning rate, gamma, epsilon) in training scripts.
- Adjust reward functions to improve learning.
- Customize UI (Tkinter, Flask, Streamlit, Pygame) to enhance user experience.

## ğŸ“œ License

This project is licensed under the MIT License. See the [LICENSE](./LICENSE) file for more details.

## ğŸ“© Contact & Contributions

- ğŸ”— [GitHub :](https://github.com/ishi3012)
- ğŸ“§ [Email :](shilpa.musale02@gmail.com)

ğŸš€ Feel free to fork, contribute, and improve these projects! ğŸ†